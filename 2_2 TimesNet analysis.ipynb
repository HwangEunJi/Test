{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df1 = pd.read_csv(\"https://raw.githubusercontent.com/ourownstory/neuralprophet-data/main/datasets_raw/wp_log_peyton_manning.csv\")\n",
    "# df1.to_csv('c:/Users/Sofia/Documents/paper/dataset/wp_log_peyton_manning.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available gpu: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "print(f\"available gpu: {torch.cuda.is_available()}\")\n",
    "\n",
    "import argparse\n",
    "\n",
    "sys.path.insert(0, 'c:/Users/Sofia/Documents/paper/code/TimesNet_code')\n",
    "from print_args import print_args\n",
    "from exp_long_term_forecasting import Exp_Long_Term_Forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "\u001b[1mBasic Config\u001b[0m\n",
      "  Task Name:          long_term_forecast  Is Training:        1                   \n",
      "  Model ID:           pm_ver1             Model:              TimesNet            \n",
      "\n",
      "\u001b[1mData Loader\u001b[0m\n",
      "  Data:               custom              Root Path:          c:/Users/Sofia/Documents/paper/dataset/\n",
      "  Data Path:          wp_log_peyton_manning.csvFeatures:           S                   \n",
      "  Target:             y                   Freq:               d                   \n",
      "  Checkpoints:        ./checkpoints/      \n",
      "\n",
      "\u001b[1mForecasting Task\u001b[0m\n",
      "  Seq Len:            96                  Label Len:          48                  \n",
      "  Pred Len:           96                  Seasonal Patterns:  Monthly             \n",
      "  Inverse:            0                   \n",
      "\n",
      "\u001b[1mModel Parameters\u001b[0m\n",
      "  Top k:              5                   Num Kernels:        6                   \n",
      "  Enc In:             1                   Dec In:             1                   \n",
      "  C Out:              1                   d model:            512                 \n",
      "  n heads:            8                   e layers:           2                   \n",
      "  d layers:           1                   d FF:               2048                \n",
      "  Moving Avg:         25                  Factor:             1                   \n",
      "  Distil:             1                   Dropout:            0.1                 \n",
      "  Embed:              timeF               Activation:         gelu                \n",
      "  Output Attention:   0                   \n",
      "\n",
      "\u001b[1mRun Parameters\u001b[0m\n",
      "  Num Workers:        10                  Itr:                1                   \n",
      "  Train Epochs:       1                   Batch Size:         32                  \n",
      "  Patience:           3                   Learning Rate:      1e-06               \n",
      "  Des:                test                Loss:               MSE                 \n",
      "  Lradj:              type1               Use Amp:            0                   \n",
      "\n",
      "\u001b[1mGPU\u001b[0m\n",
      "  Use GPU:            0                   GPU:                0                   \n",
      "  Use Multi GPU:      0                   Devices:            0                   \n",
      "\n",
      "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
      "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
      "\n",
      "Use CPU\n",
      ">>>>>>>start training : long_term_forecast_pm_ver1_TimesNet_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 1552\n",
      "val 486\n",
      "test 486\n"
     ]
    }
   ],
   "source": [
    "args = argparse.Namespace(\n",
    "    # basic config\n",
    "    task_name = 'long_term_forecast'\n",
    "    , is_training = 1\n",
    "    , model_id = 'pm_ver1'\n",
    "    , model = 'TimesNet'\n",
    "\n",
    "    # data loader\n",
    "    , data = 'custom'\n",
    "    , root_path = 'c:/Users/Sofia/Documents/paper/dataset/' ### 데이터 확인 필요\n",
    "    , data_path = 'wp_log_peyton_manning.csv' ### 데이터 확인 필요\n",
    "    , features = 'S' ### M: 다변량 -> 다변량, S: 일변량 -> 일변량, MS: 다변량 -> 일변량\n",
    "    , target = 'y'\n",
    "    , freq = 'd'\n",
    "    , checkpoints = './checkpoints/'\n",
    "\n",
    "    # forecasting task\n",
    "    , seq_len = 96\n",
    "    , label_len = 48\n",
    "    , pred_len = 96\n",
    "    , seasonal_patterns = 'Monthly'\n",
    "    , inverse = False\n",
    "\n",
    "    # inputation task ### 삭제?\n",
    "    , mask_rate = 0.25 \n",
    "\n",
    "    # anomaly detection task ### 삭제?\n",
    "    , anomaly_ratio = 0.25 \n",
    "\n",
    "    # model define\n",
    "    , top_k = 5\n",
    "    , num_kernels = 6 # N: Transformer 주요 파라미터\n",
    "    , enc_in = 1 # 사용 변수 수\n",
    "    , dec_in = 1 # 사용 변수 수\n",
    "    , c_out = 1 # 사용 변수 수\n",
    "    , d_model = 512 # Transformer 주요 파라미터\n",
    "    , n_heads = 8 # h: Transformer 주요 파라미터\n",
    "    , e_layers = 2\n",
    "    , d_layers = 1\n",
    "    , d_ff = 2048 # Transformer 주요 파라미터\n",
    "    , moving_avg = 25\n",
    "    , factor = 1\n",
    "    , distil = True\n",
    "    , dropout = 0.1\n",
    "    , embed = 'timeF'\n",
    "    , activation = 'gelu'\n",
    "    , output_attention = False ### default 없음 추가로 arg 지정 없으면 false\n",
    "\n",
    "    # optimization\n",
    "    , num_workers = 10\n",
    "    , itr = 1\n",
    "    , train_epochs = 1\n",
    "    , batch_size = 32 # 32\n",
    "    , patience = 3 #\n",
    "    , learning_rate = 0.000001\n",
    "    , des = 'test'\n",
    "    , loss = 'MSE'\n",
    "    , lradj = 'type1'\n",
    "    , use_amp = False\n",
    "\n",
    "    # GPU\n",
    "    , use_gpu = False\n",
    "    , gpu = 0\n",
    "    , use_multi_gpu = False\n",
    "    , devices = '0'\n",
    "\n",
    "    # de-stationary projector params\n",
    "    , p_hidden_dims = [128, 128]\n",
    "    , p_hidden_layers = 2\n",
    ")\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "print('Args in experiment:')\n",
    "print_args(args)\n",
    "\n",
    "Exp = Exp_Long_Term_Forecast\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # setting record of experiments\n",
    "        exp = Exp(args)  # set experiments\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.task_name,\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des, ii)\n",
    "\n",
    "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "        args.task_name,\n",
    "        args.model_id,\n",
    "        args.model,\n",
    "        args.data,\n",
    "        args.features,\n",
    "        args.seq_len,\n",
    "        args.label_len,\n",
    "        args.pred_len,\n",
    "        args.d_model,\n",
    "        args.n_heads,\n",
    "        args.e_layers,\n",
    "        args.d_layers,\n",
    "        args.d_ff,\n",
    "        args.factor,\n",
    "        args.embed,\n",
    "        args.distil,\n",
    "        args.des, ii)\n",
    "\n",
    "    exp = Exp(args)  # set experiments\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting, test=1)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # (1743, 581, 581)\n",
    "    # (1552, 486, 486)\n",
    "    # -191, -95, -95\n",
    "\n",
    "#PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43margparse\u001b[49m\u001b[38;5;241m.\u001b[39mNamespace(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# basic config\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     task_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong_term_forecast\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m     , is_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m     , model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpm_ver2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m     , model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimesNet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# data loader\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     , data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m     , root_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/ourownstory/neuralprophet-data/main/datasets_raw/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m### 데이터 확인 필요\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     , data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwp_log_peyton_manning.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m### 데이터 확인 필요\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     , features \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m### M: 다변량 -> 다변량, S: 일변량 -> 일변량, MS: 다변량 -> 일변량\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     , target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m     , freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m     , checkpoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# forecasting task\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     , seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m36\u001b[39m\n\u001b[0;32m     19\u001b[0m     , label_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m18\u001b[39m\n\u001b[0;32m     20\u001b[0m     , pred_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24\u001b[39m\n\u001b[0;32m     21\u001b[0m     , seasonal_patterns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonthly\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     22\u001b[0m     , inverse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# inputation task ### 삭제?\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     , mask_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m \n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# anomaly detection task ### 삭제?\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     , anomaly_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m \n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# model define\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     , top_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     32\u001b[0m     , num_kernels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[0;32m     33\u001b[0m     , enc_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# 사용 변수 수\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     , dec_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# 사용 변수 수\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     , c_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# 사용 변수 수\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     , d_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     , n_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m     38\u001b[0m     , e_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     39\u001b[0m     , d_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     40\u001b[0m     , d_ff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m\n\u001b[0;32m     41\u001b[0m     , moving_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[0;32m     42\u001b[0m     , factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     43\u001b[0m     , distil \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     , dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m     45\u001b[0m     , embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeF\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     46\u001b[0m     , activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgelu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     47\u001b[0m     , output_attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m### default 없음 추가로 arg 지정 없으면 false\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# optimization\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     , num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     51\u001b[0m     , itr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     52\u001b[0m     , train_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     53\u001b[0m     , batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m     54\u001b[0m     , patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     , learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m\n\u001b[0;32m     56\u001b[0m     , des \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     57\u001b[0m     , loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     58\u001b[0m     , lradj \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     59\u001b[0m     , use_amp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# GPU ### 삭제?\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     , use_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     , gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     64\u001b[0m     , use_multi_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     , devices \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0,1,2,3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# de-stationary projector params\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     , p_hidden_dims \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m]\n\u001b[0;32m     69\u001b[0m     , p_hidden_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     70\u001b[0m )\n\u001b[0;32m     72\u001b[0m args\u001b[38;5;241m.\u001b[39muse_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_gpu \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_gpu \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_multi_gpu:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'argparse' is not defined"
     ]
    }
   ],
   "source": [
    "args = argparse.Namespace(\n",
    "    # basic config\n",
    "    task_name = 'long_term_forecast'\n",
    "    , is_training = 1\n",
    "    , model_id = 'pm_ver2'\n",
    "    , model = 'TimesNet'\n",
    "\n",
    "    # data loader\n",
    "    , data = 'custom'\n",
    "    , root_path = 'c:/Users/Sofia/Documents/paper/dataset/' ### 데이터 확인 필요\n",
    "    , data_path = 'wp_log_peyton_manning.csv' ### 데이터 확인 필요\n",
    "    , features = 'S' ### M: 다변량 -> 다변량, S: 일변량 -> 일변량, MS: 다변량 -> 일변량\n",
    "    , target = 'y'\n",
    "    , freq = 'd'\n",
    "    , checkpoints = './checkpoints/'\n",
    "\n",
    "    # forecasting task\n",
    "    , seq_len = 96\n",
    "    , label_len = 48\n",
    "    , pred_len = 96\n",
    "    , seasonal_patterns = 'Monthly'\n",
    "    , inverse = False\n",
    "\n",
    "    # inputation task ### 삭제?\n",
    "    , mask_rate = 0.25 \n",
    "\n",
    "    # anomaly detection task ### 삭제?\n",
    "    , anomaly_ratio = 0.25 \n",
    "\n",
    "    # model define\n",
    "    , top_k = 10\n",
    "    , num_kernels = 6 # N: Transformer 주요 파라미터\n",
    "    , enc_in = 1 # 사용 변수 수\n",
    "    , dec_in = 1 # 사용 변수 수\n",
    "    , c_out = 1 # 사용 변수 수\n",
    "    , d_model = 512 # Transformer 주요 파라미터\n",
    "    , n_heads = 8 # h: Transformer 주요 파라미터\n",
    "    , e_layers = 2\n",
    "    , d_layers = 1\n",
    "    , d_ff = 2048 # Transformer 주요 파라미터\n",
    "    , moving_avg = 25\n",
    "    , factor = 1\n",
    "    , distil = True\n",
    "    , dropout = 0.1\n",
    "    , embed = 'timeF'\n",
    "    , activation = 'gelu'\n",
    "    , output_attention = False ### default 없음 추가로 arg 지정 없으면 false\n",
    "\n",
    "    # optimization\n",
    "    , num_workers = 10\n",
    "    , itr = 1\n",
    "    , train_epochs = 1\n",
    "    , batch_size = 32 # 32\n",
    "    , patience = 3 #\n",
    "    , learning_rate = 0.000001\n",
    "    , des = 'test'\n",
    "    , loss = 'MSE'\n",
    "    , lradj = 'type1'\n",
    "    , use_amp = False\n",
    "\n",
    "    # GPU\n",
    "    , use_gpu = False\n",
    "    , gpu = 0\n",
    "    , use_multi_gpu = False\n",
    "    , devices = '0'\n",
    "\n",
    "    # de-stationary projector params\n",
    "    , p_hidden_dims = [128, 128]\n",
    "    , p_hidden_layers = 2\n",
    ")\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "print('Args in experiment:')\n",
    "print_args(args)\n",
    "\n",
    "Exp = Exp_Long_Term_Forecast\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # setting record of experiments\n",
    "        exp = Exp(args)  # set experiments\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.task_name,\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des, ii)\n",
    "\n",
    "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "        args.task_name,\n",
    "        args.model_id,\n",
    "        args.model,\n",
    "        args.data,\n",
    "        args.features,\n",
    "        args.seq_len,\n",
    "        args.label_len,\n",
    "        args.pred_len,\n",
    "        args.d_model,\n",
    "        args.n_heads,\n",
    "        args.e_layers,\n",
    "        args.d_layers,\n",
    "        args.d_ff,\n",
    "        args.factor,\n",
    "        args.embed,\n",
    "        args.distil,\n",
    "        args.des, ii)\n",
    "\n",
    "    exp = Exp(args)  # set experiments\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting, test=1)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # (1743, 581, 581)\n",
    "    # (1552, 486, 486)\n",
    "    # -191, -95, -95\n",
    "\n",
    "#PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.5937596 ],\n",
       "        [-0.5619411 ],\n",
       "        [-0.49291155],\n",
       "        ...,\n",
       "        [-0.73052526],\n",
       "        [-0.7330429 ],\n",
       "        [-0.6434702 ]],\n",
       "\n",
       "       [[-0.67306894],\n",
       "        [-0.63015544],\n",
       "        [-0.692971  ],\n",
       "        ...,\n",
       "        [-0.65710396],\n",
       "        [-0.69250536],\n",
       "        [-0.73098063]],\n",
       "\n",
       "       [[-0.7137954 ],\n",
       "        [-0.6958552 ],\n",
       "        [-0.8358108 ],\n",
       "        ...,\n",
       "        [-0.84160465],\n",
       "        [-0.8596547 ],\n",
       "        [-0.85254514]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.25277817],\n",
       "        [ 0.25004655],\n",
       "        [ 0.10866481],\n",
       "        ...,\n",
       "        [ 0.68023026],\n",
       "        [ 0.67217994],\n",
       "        [ 0.49185258]],\n",
       "\n",
       "       [[ 0.3778791 ],\n",
       "        [ 0.38807967],\n",
       "        [ 0.397388  ],\n",
       "        ...,\n",
       "        [ 0.65338564],\n",
       "        [ 0.82365227],\n",
       "        [ 0.4054999 ]],\n",
       "\n",
       "       [[ 0.19139388],\n",
       "        [ 0.26632437],\n",
       "        [ 0.35956416],\n",
       "        ...,\n",
       "        [ 0.764732  ],\n",
       "        [ 0.58714426],\n",
       "        [ 0.4454377 ]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = argparse.Namespace(\n",
    "    # basic config\n",
    "    task_name = 'long_term_forecast'\n",
    "    , is_training = 1\n",
    "    , model_id = 'pm_ver3'\n",
    "    , model = 'TimesNet'\n",
    "\n",
    "    # data loader\n",
    "    , data = 'custom'\n",
    "    , root_path = 'c:/Users/Sofia/Documents/paper/dataset/' ### 데이터 확인 필요\n",
    "    , data_path = 'wp_log_peyton_manning.csv' ### 데이터 확인 필요\n",
    "    , features = 'S' ### M: 다변량 -> 다변량, S: 일변량 -> 일변량, MS: 다변량 -> 일변량\n",
    "    , target = 'y'\n",
    "    , freq = 'd'\n",
    "    , checkpoints = './checkpoints/'\n",
    "\n",
    "    # forecasting task\n",
    "    , seq_len = 96\n",
    "    , label_len = 48\n",
    "    , pred_len = 96\n",
    "    , seasonal_patterns = 'Monthly'\n",
    "    , inverse = False\n",
    "\n",
    "    # inputation task ### 삭제?\n",
    "    , mask_rate = 0.25 \n",
    "\n",
    "    # anomaly detection task ### 삭제?\n",
    "    , anomaly_ratio = 0.25 \n",
    "\n",
    "    # model define\n",
    "    , top_k = 15\n",
    "    , num_kernels = 6 # N: Transformer 주요 파라미터\n",
    "    , enc_in = 1 # 사용 변수 수\n",
    "    , dec_in = 1 # 사용 변수 수\n",
    "    , c_out = 1 # 사용 변수 수\n",
    "    , d_model = 512 # Transformer 주요 파라미터\n",
    "    , n_heads = 8 # h: Transformer 주요 파라미터\n",
    "    , e_layers = 2\n",
    "    , d_layers = 1\n",
    "    , d_ff = 2048 # Transformer 주요 파라미터\n",
    "    , moving_avg = 25\n",
    "    , factor = 1\n",
    "    , distil = True\n",
    "    , dropout = 0.1\n",
    "    , embed = 'timeF'\n",
    "    , activation = 'gelu'\n",
    "    , output_attention = False ### default 없음 추가로 arg 지정 없으면 false\n",
    "\n",
    "    # optimization\n",
    "    , num_workers = 10\n",
    "    , itr = 1\n",
    "    , train_epochs = 1\n",
    "    , batch_size = 32 # 32\n",
    "    , patience = 3 #\n",
    "    , learning_rate = 0.000001\n",
    "    , des = 'test'\n",
    "    , loss = 'MSE'\n",
    "    , lradj = 'type1'\n",
    "    , use_amp = False\n",
    "\n",
    "    # GPU\n",
    "    , use_gpu = False\n",
    "    , gpu = 0\n",
    "    , use_multi_gpu = False\n",
    "    , devices = '0'\n",
    "\n",
    "    # de-stationary projector params\n",
    "    , p_hidden_dims = [128, 128]\n",
    "    , p_hidden_layers = 2\n",
    ")\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "print('Args in experiment:')\n",
    "print_args(args)\n",
    "\n",
    "Exp = Exp_Long_Term_Forecast\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # setting record of experiments\n",
    "        exp = Exp(args)  # set experiments\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.task_name,\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des, ii)\n",
    "\n",
    "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "        args.task_name,\n",
    "        args.model_id,\n",
    "        args.model,\n",
    "        args.data,\n",
    "        args.features,\n",
    "        args.seq_len,\n",
    "        args.label_len,\n",
    "        args.pred_len,\n",
    "        args.d_model,\n",
    "        args.n_heads,\n",
    "        args.e_layers,\n",
    "        args.d_layers,\n",
    "        args.d_ff,\n",
    "        args.factor,\n",
    "        args.embed,\n",
    "        args.distil,\n",
    "        args.des, ii)\n",
    "\n",
    "    exp = Exp(args)  # set experiments\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting, test=1)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # (1743, 581, 581)\n",
    "    # (1552, 486, 486)\n",
    "    # -191, -95, -95\n",
    "\n",
    "#PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.2570767 ],\n",
       "        [-1.1501942 ],\n",
       "        [-0.8994773 ],\n",
       "        ...,\n",
       "        [ 2.3007433 ],\n",
       "        [ 0.7759804 ],\n",
       "        [ 0.6811341 ]],\n",
       "\n",
       "       [[-1.1501942 ],\n",
       "        [-0.8994773 ],\n",
       "        [-0.8532578 ],\n",
       "        ...,\n",
       "        [ 0.7759804 ],\n",
       "        [ 0.6811341 ],\n",
       "        [ 1.0926564 ]],\n",
       "\n",
       "       [[-0.8994773 ],\n",
       "        [-0.8532578 ],\n",
       "        [-0.53020257],\n",
       "        ...,\n",
       "        [ 0.6811341 ],\n",
       "        [ 1.0926564 ],\n",
       "        [ 0.5694369 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.49144554],\n",
       "        [-0.38287783],\n",
       "        [-0.9473819 ],\n",
       "        ...,\n",
       "        [-0.39876577],\n",
       "        [ 1.354567  ],\n",
       "        [ 2.6302981 ]],\n",
       "\n",
       "       [[-0.38287783],\n",
       "        [-0.9473819 ],\n",
       "        [ 0.18090408],\n",
       "        ...,\n",
       "        [ 1.354567  ],\n",
       "        [ 2.6302981 ],\n",
       "        [ 1.1764293 ]],\n",
       "\n",
       "       [[-0.9473819 ],\n",
       "        [ 0.18090408],\n",
       "        [ 0.71411365],\n",
       "        ...,\n",
       "        [ 2.6302981 ],\n",
       "        [ 1.1764293 ],\n",
       "        [ 0.89417726]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
